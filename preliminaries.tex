In this chapter we briefly present basic concepts and facts from mathematics and computer science
that we use throughout this thesis.
This chapter is divided into two sections.
The first one is a short revision of necessary mathematics.
The second section revises basics ideas of, and builds intuition regarding, computational complexity theory.
It also introduces some \np-complete decision problems for further use.

%This chapter might be skipped and used as a reference only when necessary.

\section{Mathematics}

Table \ref{symbols} presents symbol that we use in this work.

\begin{table} \centering
\begin{tabular}{| l | l |} \hline
	$\mathbb{N}_0$	& natural numbers including zero \\ \hline
	$\mathbb{N}_+$	& positive natural numbers \\ \hline
	$\mathbb{R}$	& real numbers \\ \hline
	$\mathbb{R}_0^+$& non-negative real numbers \\ \hline
	$\mathbb{P}$	& prime numbers \\ \hline
	$\sum$	& sum \\ \hline 
	$\bigcup \cdot$	& union of elements of set\\ \hline
	$\abs{\cdot}$	& set cardinality \\ \hline
	$2^\cdot$		& family of subsets \\ \hline
	$f''$			& second derivative of function $f$ \\ \hline
  $ a | b$              & $a$ divides $b$ \\ \hline
\end{tabular}
\caption{Mathematical symbols used throughout the work.} \label{symbols}
\end{table}

We need the notion of total order to model voters' preferences.

\begin{defn}[total order]
A total order over set $X$ is a binary relation $\succ$ on $X$ which~is:
\begin{itemize}
	\item transitive, i.e. $\forall a,b,c \in X: a \succ b \land b \succ c \Rightarrow a \succ c$,
	\item antisymmetric, i.e. $\forall a,b \in X: a \succ b \land b \succ a \Rightarrow a=b $,
	\item total, i.e. $\forall a,b \in X: a \succ b \lor b \succ a$.
\end{itemize}
\end{defn}

We will use the following to define a useful subrelation of total order.

\begin{defn}[transitive closure]
Transitive closure $R^*$ of relation $R$ is a minimal transitive relation 
such that $R^*$ is a superset of $R$.
\end{defn}

We define predicates to use them for recursive boolean functions.

\begin{defn}[predicate]
A predicate is a function $f$ with codomain $\{true, false\}$,
where $true$ is the logical truth and $false$ is falsity.
\end{defn}

A multiset is a generalization of the notion of a set that can hold multiple instances of the same element.

\begin{defn}[multiset]
A multiset is a pair $M = (X, c)$, where $X$ is some set and $c:X \rightarrow \mathbb{N}_0$
is a multiplicity function.
That is, for each $x \in X$, $c(x)$ denotes the number of occurrences of $x$ in $M$.
\end{defn}

For multiset $M$ we say that $x \in M$ when $c(x) > 0$.

We also generalize the notion of set union to multiset union.

\begin{defn}[multiset union]
We say that multiset $M = (X, c)$ is a multiset union of sets from family $F = \{S_1, ..., S_n\}$
if $M = \bigcup F$ and for each $x \in X$ we have that $c(x) = \abs{\{S \in F : x \in S\}}$.
\end{defn}

Set partition is the core of our work.
We treat detecting clones as partitioning the set of candidates.

\begin{defn}[set partition]
A partition of a set $X$ is a family $F$ of non-empty subsets of $X$
such that for every $a \in X$ there is exactly one $Y \in F$ such that $a \in Y$.
\end{defn}

We will model our problems with graphs.
More background on described in Wilson's classical book \cite{graphtheory}.

\begin{defn}[graph]
A graph $G$ is an ordered pair $(V,E)$, where $V$ is the set of vertices and $E$ is the set of edges.
Each edge is a 2-element subset of $V$.
\end{defn}

\begin{defn}[clique]
Let $G=(V,E)$ be a graph.
We say that a subset $C \subset V$ of the set of vertices is a clique if
for each $u,v \in C$ it holds that $\{u,v\} \in E$.
\end{defn}

\begin{defn}[multigraph]
A multigraph $G$ is an ordered pair $(V,E)$ of a set $V$ of vertices and a multiset $E$ of edges,
where the edges are defined in the same way as for graphs.
\end{defn}

\begin{defn}[induced submultigraph]
Multigraph $(V', E')$ is a submultigraph of multigraph $(V,E)$ induced by $V'$
if $V' \subset V$, $E' \subset E$, and for each $u,v \in V'$ 
the number of occurrences of $\{u,v\}$ in $E'$ is equal to the number of occurrences of $\{u,v\}$ in $E$.
\end{defn}

\begin{defn}[Hamiltonian path]
A Hamiltionian path in (multi)graph $(V,E)$
is a sequence of edges $\{u_1, u_2\}, \{u_2, u_3\} ..., \{u_{n-1}, u_n\}$,
such that for each $i=1,...,n-1$ we have $\{u_i, u_{i+1}\} \in E$.
\end{defn}


The following theorem states that prime number are dense.
We will need that to set an upper bound on the smallest $p \in \mathbb{P}$
bigger that some $n \in \mathbb{N}$.

\begin{thm}[Bertrandâ€“Chebyshev] \label{bertrand-chebyshev}
For any integer $n>1$ there exists $p \in \mathbb{P}$ such that $n < p < 2n$.
\end{thm}

Its proof can be found in Galvin's work \cite{bertrand}.

\begin{thm} \label{zp}
Let $p$ be a prime number and $a$ some positive integer less than $p$.
We have that values $a, 2a, ..., pa$ divided modulo $p$ give all the remainders from the set $\{0, ..., p-1\}$.
\end{thm}

\begin{proof}
It suffices to show that every $ia$ and $ja$ for $i,j \in \{1, ..., p\}, i \neq j$,
have different remainders from division modulo $p$.
If some $i$ and $j$ had the same remainders,
then we would have $p | ia - ja$, $p | (i-j)a$, and $p | i-j$, which is impossible.
\end{proof}

The following are definitions necessary to formulate an inequality which will be useful later.

\begin{defn}[strictly convex function]
We say that a function $f:\mathbb{R}\rightarrow\mathbb{R}$ is strictly convex on an interval $I \subset \mathbb{R}$
if for each $x_1, x_2 \in I$ and $t \in [0,1]$ it holds that $f(t x_1 + (1-t) x_2) < tf(x_1) + (1-t)f(x_2)$.
\end{defn}

The next property is a convenient way of proving that a function is strictly convex.

\begin{prp}
A twice-differentiable function $f:\mathbb{R}\rightarrow\mathbb{R}$
that for each $x$ on interval $I \subset \mathbb{R}$ has $f''(x) > 0$
is strictly convex on $I$.
\end{prp}

\begin{defn}[majorization]
We say that sequence $(a_1, ..., a_n) \in \mathbb{R}^n, a_1 \geq a_2 \geq ... \geq a_n$,
majorizes sequence $(b_1, ..., b_n) \in \mathbb{R}^n, b_1 \geq b_2 \geq ... \geq b_n$,
if the following conditions hold:
\begin{itemize}
	\item $\sum_{i=1}^n a_i = \sum_{i=1}^n b_i$ and
	\item $\sum_{i=1}^k a_i \geq \sum_{i=1}^k b_i$ $\forall k \in \{ 1, ..., n\}$.
\end{itemize}
\end{defn}

Finally the Karamata's inequality formalizes a very intuitive phenomenon.

\begin{thm}[Karamata's inequality] \label{thm:Kar}
If function $f:\mathbb{R}\rightarrow\mathbb{R}$ is strictly convex on interval~$I \subset \mathbb{R}$,
sequence $(a_i) \in I^n$ majorizes sequence $(b_i) \in I^n$,
and $(a_1, ..., a_n) \neq (b_1, ..., b_n)$, then
$\sum_{i=1}^n f(a_i) > \sum_{i=1}^n f(b_i)$.
\end{thm}

A proof of the equality can be found in Kadelburg's et al. work \cite{karamata}.

\section{Complexity Theory}

We will not give full introduction to the computational complexity theory here,
but instead we will review the most important notions.
Papadimitriou's \cite{compcomplexity}, and Garey's and Johnson's \cite{computersandintractability} textbooks
contain more complete and more formal descriptions of the topic.

We model algorithms through the notion of a \textit{Turing machine}.
Computation means execution of a Turing machine on a given input.
The Church-Turing Thesis states informally what a Turing machine can do.

\begin{cnj}[Church-Turing Thesis]
Computability by Turing machine is equivalent to intuitive notion of computability.
\end{cnj}

The next definition formalizes the notion of a problem.

\begin{defn}[decision problem]
Decision problem is a function that transforms an input into one of two possible answers,
\textsc{yes} or \textsc{no}.
\end{defn}

The following defines when a Turing machine solves a given prolem.

\begin{defn}[solvability by a Turing machine]
We say that a Turing machine solves a decision problem $A$ if for each input $x$
it ends its execution in a state equal to $A(x)$.
\end{defn}

\begin{defn}[polynomial-time Turing machine]
A polynomial-time Turing machine is a Turing machine $M$ for which there are integers $k$ and $c$
such that for every input of size $n$ machine $M$ executed on this input makes at most $c n^k$ steps.
\end{defn}

We define \p as the class of problems solvable by polynomial-time Turing machines.

\begin{defn}[class \p]
Decision problem $A$ belongs to class \p if there is a polynomial-time Turing machine that solves $A$.
\end{defn}

A reduction is an algorithm that transforms an input of one problem
into an input of another one while preserving the answer.

\begin{defn}[polynomial-time reduction]
A polynomial-time reduction from problem $A$ to problem $B$ is a polynomial-time Turing machine
that transforms every \textsc{yes}-input of $A$ into some \textsc{yes}-input of $B$,
and every \textsc{no}-input of $A$ into some \textsc{no}-input of $B$.
\end{defn}

If there is a polynomial-time reduction from problem $A$ to problem $B$,
then we say that $A$ polynomially reduces to $B$.

Here we present some simple facts about reductions.

\begin{rmrk}\label{tran-red}
Relation "reduces polynomially to" is transitive.
\end{rmrk}

\begin{rmrk}\label{p-red}
If problem $A$ reduces polynomially to problem $B$ and $B \in \p$ then $A \in \p$.
\end{rmrk}

\np is the complexity class of problems to which \textsc{yes}-inputs are polynomially verifiable.
We verify an input by augmenting it with a polynomial-sized proof.

\begin{defn}[\np]
Problem $A$ belongs to \np if there is a Turing machine $M$ and integers $k$ and $c$ such that
for each $n$-sized \textsc{yes}-input $x$ of $A$,
$M$ answers \textsc{yes} to input $(x,y)$ for some $y$ whose size is not greater than $c n^k$,
and for each $n$-sized \textsc{no}-input $z$ of $A$,
$M$ answers \textsc{no} to input $(z,w)$ for every $w$ whose size is not greater than $c n^k$.
\end{defn}

It remains an open problem whether $\text{\textsc{P}}\neq\np$.
This is why we define \np-hard as the complexity class of problems as hard or harder than every problem in \np.

\begin{defn}[\np-hard]
Problem $A$ is \np-hard if for each problem $B \in \np$
there is a polynomial-time reduction from $B$ to $A$.
\end{defn}

We are often interested in those \np-hard problems that remain in \np.

\begin{defn}[\np-complete]
Problem $A$ is \np-complete if $A$ is both in \np and is \np-hard.
\end{defn}

The following captures why proving \np-completeness of a problem is valuable.

\begin{rmrk}
If an \np-complete problem $A$ belongs to \p then using remarks \ref{tran-red} and \ref{p-red}
we have that $\p = \np$.
\end{rmrk}

This, using contraposition, gives us that if $\p \neq \np$ then \np-complete problems are not in \p.

We have a very convenient method of proving that a problem is \np-hard.

\begin{rmrk}
If an \np-hard problem $A$ reduces polynomially to problem $B$, then also $B$ is \np-hard.
\end{rmrk}

With that we only need to show a polynomial-time reduction from a well-known \np-hard problem
to our problem to prove that our problem is \np-hard.
Now we will introduce some \np-hard (indeed, \np-complete) problems.

\begin{problem}{Exact3Cover (X3C)}
	Input: Set $X$, family $S$ of three-element subsets of $X$, $\vert{X}\vert = 3n$.

	Question: Is there an $n$-element subset $A \subset S$ such that $\bigcup A = X$?
\end{problem}

\begin{thm}
\textsc{X3C} is \np-complete.
\end{thm}

Its proof can be found in Garey's and Johnson's textbook \cite{computersandintractability}.

\begin{problem}{Clique}
    Input: Graph $G = (V, E)$, integer $c$.

    Question: Is there a subgraph of $G$ that is a clique of size $c$?
\end{problem}

\begin{thm}
\textsc{Clique} is \np-complete.
\end{thm}

Again, its proof in included in the textbook \cite{computersandintractability}.


We will show an example of an \np-completeness proof by giving a reduction.

\begin{problem}{GraphPartition}
Input: Graph $G = (V, E)$, integer $k$ and $l$.

Question: Is it possible to partition $V$ into $k$ parts so that the number of edges
whose vertices belong to the same part is at least $l$?
\end{problem}

We will call an edge whose vertices belong to the same part an internal edge
and the set of all internal edges an intra-part edges.

\begin{thm} \label{gp-np}
\textsc{GraphPartition} is \np-complete.
\end{thm}

\begin{proof}
\textsc{GraphPartition} is clearly in \np,
as given the partition we may verify its properties in a polynomial time.
To prove \np-hardness we will show a reduction from the \textsc{Clique} problem.

We are given graph $G$ and integer $c$.
Let us denote $n = \abs{S}$.
Let us leave $G$ unchanged and take $k = n-c+1$ and $l = c(c-1)/2$.
We will show that this is a valid reduction to \textsc{GraphPartition}.

Let us first consider the case where the answer to the \textsc{Clique} problem is \textsc{yes},
i.e., $G$ contains a clique consisting of $c$ vertices $C$.
We may then partition $V$ into $k$ parts:
$C$ istelf and $n-c$ singletons of the remaining vertices from $V \backslash C$.
The number of intra-part edges equals $c(c-1)/2$ for part $C$ and $0$ for the remaining parts.
This gives $l$ in total, so the answer to \textsc{GraphPartition} problem is \textsc{yes} as well.

Now it suffices to show that when there is no $c$-size clique in $G$,
then the answer to the reduced problem is \textsc{no}.
In that case every $c$-size part of $V$ has fewer than $l$ internal edges,
so partitioning $V$ into $k$ parts of sizes $(c, 1, ..., 1)$ will lead to fewer than $l$ intra-part edges.
Now let us consider partitioning $P$ of $V$ into parts that form a different sequence $S$ of sizes.
Let us denote the number of intra-part edges in $P$ by $e$.
Every part of size $m$ has at most $f(m) = m(m-1)/2$ internal edges,
this number is reached only when a part forms a clique.
Function $f$ is strictly convex, because $f''(x) = 1 > 0$ and $(c,1,...,1)$ majorizes $s$,
so we can use inequality \eqref{thm:Kar} for $f$ and both sequences.
This gives us the following upper limit on $e$:
$$e \leq \sum_{s\in{S}} f(s) < f(c) + f(1) + ... + f(1) = l$$
We thus get that each partition has less than $l$ internal edges,
so the answer to the \textsc{GraphPartition} problem remains \textsc{no}.
\end{proof}
